"""
This script trains a model for rod mask generation on the c4m dataset.
The procedure is an extended version of a previously used network that has
been implemented using the Matterport implementation of the mask RCNN network
architecture.
Instead of the standard mask head, this network uses a PointRend network for
the segmentation mask generation.

Author:     Adrian Niemann (adrian.niemann@ovgu.de)
Date:       10.08.2022
"""

import os
import numpy as np

from detectron2.config import CfgNode
import detectron2.data.transforms as T
from detectron2.projects import point_rend      # Don't remove, registers
                                                # model parts in detectron2
from runners import training
from utils import datasets as ds
import utils.custom_augmentations as ca
import utils.helper_funcs as hf


def train_heads(output_base: str, config: dict, weights: str = None) -> dict:
    """Training Step 1

    Trains only the heads of the model, i.e. excludes backbone and box
    predictor from updating during training.

    Parameters
    ----------
    output_base : str
        Path to the main output directory. Will serve as the location for the
        output folder generated by this training step.
    config : dict
        Basic configuration of the model training. Will be adapted in this
        function.
    weights : str, optional
        Path to a *.pkl file containing weights to be used for the trained
        model.

    Returns
    -------
    dict
        Configuration used for training the model in this training step.
    """
    config["freeze_layers"] = ["backbone", "box_predictor"]
    previous_output = config["output_dir"]
    config["output_dir"] = os.path.join(output_base, "heads")
    if weights is None:
        config["configuration"].MODEL.WEIGHTS = os.path.join(
            previous_output, "model_final.pth")
    else:
        config["configuration"].MODEL.WEIGHTS = weights

    image_no = hf.get_dataset_size(config["train_set"])
    config["configuration"].SOLVER.MAX_ITER = int(
        hf.get_iters(config["configuration"], image_no, desired_epochs=300))
    config["configuration"].SOLVER.BASE_LR = 0.001
    config["configuration"].INPUT.CROP.ENABLED = True
    config["configuration"].INPUT.MIN_SIZE_TRAIN = 512

    training.run_training(**config)
    return config


def train_all_s1(output_base: str, config: dict, weights: str = None) -> dict:
    """Training Step 2

    Trains all layers of the model with the same learning rate as in step 1.

    Parameters
    ----------
    output_base : str
        Path to the main output directory. Will serve as the location for the
        output folder generated by this training step.
    config : dict
        Basic configuration of the model training. Will be adapted in this
        function.
    weights : str, optional
        Path to a *.pkl file containing weights to be used for the trained
        model.

    Returns
    -------
    dict
        Configuration used for training the model in this training step.
    """
    config["freeze_layers"] = []
    previous_output = config["output_dir"]
    config["output_dir"] = os.path.join(output_base, "all_1")
    if weights is None:
        config["configuration"].MODEL.WEIGHTS = os.path.join(
            previous_output, "model_final.pth")
    else:
        config["configuration"].MODEL.WEIGHTS = weights
    image_no = hf.get_dataset_size(config["train_set"])
    config["configuration"].SOLVER.MAX_ITER = int(
        hf.get_iters(config["configuration"], image_no, desired_epochs=450))

    training.run_training(**config)
    return config


def train_all_s2(output_base: str, config: dict, weights: str = None) -> dict:
    """Training Step 3

    Trains all layers of the model but over more epochs and with a smaller
    learning rate than in step 2.

    Parameters
    ----------
    output_base : str
        Path to the main output directory. Will serve as the location for the
        output folder generated by this training step.
    config : dict
        Basic configuration of the model training. Will be adapted in this
        function.
    weights : str, optional
        Path to a *.pkl file containing weights to be used for the trained
        model.

    Returns
    -------
    dict
        Configuration used for training the model in this training step.
    """
    config["freeze_layers"] = []
    previous_output = config["output_dir"]
    config["output_dir"] = os.path.join(output_base, "all_2")
    if weights is None:
        config["configuration"].MODEL.WEIGHTS = os.path.join(
            previous_output, "model_final.pth")
    else:
        config["configuration"].MODEL.WEIGHTS = weights
    image_no = hf.get_dataset_size(config["train_set"])
    config["configuration"].SOLVER.MAX_ITER = int(
        hf.get_iters(config["configuration"], image_no, desired_epochs=600))
    config["configuration"].SOLVER.BASE_LR = 0.0004

    training.run_training(**config)
    return config


def train_all_s3(output_base: str, config: dict, weights: str = None) -> dict:
    """Training Step 4

    Trains all layers of the model but over more epochs and with a smaller
    learning rate than in step 3.

    Parameters
    ----------
    output_base : str
        Path to the main output directory. Will serve as the location for the
        output folder generated by this training step.
    config : dict
        Basic configuration of the model training. Will be adapted in this
        function.
    weights : str, optional
        Path to a *.pkl file containing weights to be used for the trained
        model.

    Returns
    -------
    dict
        Configuration used for training the model in this training step.
    """
    config["freeze_layers"] = []
    previous_output = config["output_dir"]
    config["output_dir"] = os.path.join(output_base, "all_3")
    if weights is None:
        config["configuration"].MODEL.WEIGHTS = os.path.join(
            previous_output, "model_final.pth")
    else:
        config["configuration"].MODEL.WEIGHTS = weights
    image_no = hf.get_dataset_size(config["train_set"])
    config["configuration"].SOLVER.MAX_ITER = int(
        hf.get_iters(config["configuration"], image_no, desired_epochs=750))
    config["configuration"].SOLVER.BASE_LR = 0.0001

    training.run_training(**config)
    return config


def train_point_rend(output_base: str, config: dict, weights: str = None) -> \
        dict:
    """Training Step 5

    Trains only the PointRend section of the model.

    Parameters
    ----------
    output_base : str
        Path to the main output directory. Will serve as the location for the
        output folder generated by this training step.
    config : dict
        Basic configuration of the model training. Will be adapted in this
        function.
    weights : str, optional
        Path to a *.pkl file containing weights to be used for the trained
        model.

    Returns
    -------
    dict
        Configuration used for training the model in this training step.
    """
    config["freeze_layers"] = ["backbone", "box_predictor", "box_head",
                               "proposal_generator"]
    previous_output = config["output_dir"]
    config["output_dir"] = os.path.join(output_base, "pr_head")
    if weights is None:
        config["configuration"].MODEL.WEIGHTS = os.path.join(
            previous_output, "model_final.pth")
    else:
        config["configuration"].MODEL.WEIGHTS = weights
    image_no = hf.get_dataset_size(config["train_set"])
    config["configuration"].SOLVER.MAX_ITER = int(
        hf.get_iters(config["configuration"], image_no, desired_epochs=300))

    training.run_training(**config)
    return config


def init_cfg() -> dict:
    """Initialize the configuration for training.

    Returns
    -------
    dict
        Configuration that can be used for training as:
            `training.run_training(**configuration)`
    """
    # Set up known dataset(s) for use with Detectron2 ##########################
    data_folder = "../../datasets/rods_c4m"
    metadata_file = "/via_export_json.json"
    train_data = ds.DataSet("c4m_train", data_folder + "/train",
                            metadata_file)
    val_data = ds.DataSet("c4m_val", data_folder + "/val", metadata_file)
    # Register datasets to Detectron2
    classes = ["blue", "green", "orange", "purple", "red", "yellow",
               "black", "lilac", "brown"]
    try:
        ds.register_dataset(train_data, classes=classes)
        ds.register_dataset(val_data, classes=classes)
    except AssertionError as e:
        # Datasets are already registered
        print(e)
    image_no = hf.get_dataset_size(train_data)

    # Set up training configuration ############################################
    # Load a *.yaml file with static configurations
    cfg = CfgNode(CfgNode.load_yaml_with_base(
        "../../base_configs/rod_detection.yaml"))

    cfg.DATASETS.TRAIN = [train_data.name]
    cfg.DATASETS.TEST = [val_data.name]

    # control the GPU memory load
    cfg.SOLVER.IMS_PER_BATCH = 1
    # No warm-up and constant lr
    cfg.SOLVER.WARMUP_ITERS = 0
    cfg.SOLVER.STEPS = ()
    cfg.SOLVER.CHECKPOINT_PERIOD = 5 * image_no

    # add computed values to the configuration,
    cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(
        ds.get_dataset_classes(train_data))
    cfg.MODEL.BACKBONE.FREEZE_AT = 0
    cfg.TEST.EVAL_PERIOD = int(image_no / cfg.SOLVER.IMS_PER_BATCH)
    counts = hf.get_object_counts(val_data)
    cfg.TEST.DETECTIONS_PER_IMAGE = int(1.5 * np.max(counts))

    # create a list of image augmentations to use ##############################
    augmentations = [
        ca.SomeOf([
            T.RandomFlip(horizontal=True, vertical=False),
            T.RandomFlip(horizontal=False, vertical=True),
            T.RandomRotation([90, 180, 270], expand=False,
                             sample_style="choice"),
            T.RandomRotation([15, 30, 45, 60, 75], expand=False,
                             sample_style="choice"),
            ca.MultiplyAugmentation(mul=(0.85, 1.15)),
            ca.GaussianBlurAugmentation(sigmas=(0.0, 2.0)),
            ca.SharpenAugmentation(alpha=(0.0, 0.5), lightness=(0.8, 1.15))
        ],
            lower=0, upper=3)
    ]

    return {
        "train_set": train_data,
        "val_set": val_data,
        "configuration": cfg,
        "output_dir": "",
        "resume": True,
        "visualize": False,
        "img_augmentations": augmentations,
        "freeze_layers": []
    }


def init_cfg_pr() -> dict:
    """Initialize the configuration for training the PointRend network part.

    Returns
    -------
    dict
        Configuration that can be used for training as:
            `training.run_training(**configuration)`
    """
    # Set up known dataset(s) for use with Detectron2 ##########################
    data_folder = "../../datasets/rods_c4m"
    metadata_file = "/via_export_json.json"
    train_data = ds.DataSet("c4m_train", data_folder + "/train",
                            metadata_file)
    val_data = ds.DataSet("c4m_val", data_folder + "/val", metadata_file)
    # Register datasets to Detectron2
    classes = ["blue", "green", "orange", "purple", "red", "yellow",
               "black", "lilac", "brown"]
    try:
        ds.register_dataset(train_data, classes=classes)
        ds.register_dataset(val_data, classes=classes)
    except AssertionError as e:
        # Datasets are already registered
        print(e)

    # Set up training configuration ############################################
    # Load a *.yaml file with static configurations
    cfg = CfgNode(CfgNode.load_yaml_with_base(
        "../../base_configs/rod_detection_PR.yaml"))

    cfg.DATASETS.TRAIN = [train_data.name]
    cfg.DATASETS.TEST = [val_data.name]

    # add computed values to the configuration,
    image_no = hf.get_dataset_size(train_data)
    cfg.TEST.EVAL_PERIOD = int(image_no / cfg.SOLVER.IMS_PER_BATCH)
    cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(
        ds.get_dataset_classes(train_data))
    # No warm-up and constant lr
    cfg.SOLVER.WARMUP_ITERS = 0
    cfg.SOLVER.STEPS = ()
    cfg.SOLVER.CHECKPOINT_PERIOD = 5 * image_no
    augmentations = [
        ca.SomeOf([
            T.RandomFlip(horizontal=True, vertical=False),
            T.RandomFlip(horizontal=False, vertical=True),
            T.RandomRotation([90, 180, 270], expand=False,
                             sample_style="choice"),
            T.RandomRotation([15, 30, 45, 60, 75], expand=False,
                             sample_style="choice"),
            ca.MultiplyAugmentation(mul=(0.85, 1.15)),
            ca.GaussianBlurAugmentation(sigmas=(0.0, 2.0)),
            ca.SharpenAugmentation(alpha=(0.0, 0.5), lightness=(0.8, 1.15))
        ],
            lower=0, upper=3)
    ]
    cfg.INPUT.CROP.ENABLED = True
    cfg.INPUT.MIN_SIZE_TRAIN = 512
    cfg.MODEL.BACKBONE.FREEZE_AT = 0

    # PointRend settings
    cfg.MODEL.ROI_MASK_HEAD.POINT_HEAD_ON = True
    cfg.MODEL.POINT_HEAD.NUM_CLASSES = len(
        ds.get_dataset_classes(train_data))

    return {
        "train_set": train_data,
        "val_set": val_data,
        "configuration": cfg,
        "output_dir": "",
        "resume": True,
        "visualize": False,
        "img_augmentations": augmentations,
        "freeze_layers": []
    }


def main():
    """Set up the experiment(s) and invoke the training procedure."""

    output = "./rod_detector"
    init_weights = "https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x/138205316/model_final_a3ec72.pkl"
    cfg = init_cfg()
    cfg = train_heads(output, cfg, init_weights)
    cfg = train_all_s1(output, cfg)
    cfg = train_all_s2(output, cfg)
    cfg = train_all_s3(output, cfg)
    weights = os.path.join(cfg["output_dir"], "model_final.pth")
    cfg_point_rend = init_cfg_pr()
    cfg = train_point_rend(output, cfg_point_rend, weights)


if __name__ == "__main__":
    main()
